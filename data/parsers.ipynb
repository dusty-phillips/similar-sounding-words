{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similar sounding words\n",
    "\n",
    "This is a list of similar sounding words that I have collected from various sources on the web and added to as I find new pairs.\n",
    "\n",
    "Unlike most homophone, homograph, and homonym resources this list is not targeting ESL or educational use. Instead it is designed for finding common errors in speech recognition texts. Specifically I use it with [Caster](https://caster.readthedocs.io/en/latest/) for voice programming.\n",
    "\n",
    "I currently have five different sources. I've downloaded their contents as text files, or in one case HTML and parsed appropriately. I have also linked to the original location of these files both inside the files and in the headings between Jupyter cells below.\n",
    "\n",
    "Unfortunately I wasn't thinking about reproducibility when I started this project, so most of the text files have had a bit of light preprocessing in a text editor. Given that I don't expect these source lists to change in the future, I don't think it will be a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup # pip install beautifulsoup4\n",
    "from disjoint_set import DisjointSet # pip install disjoint-set\n",
    "import re\n",
    "from pprint import pformat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [7esl.html](https://7esl.com/homophones/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = open(\"7esl.html\", encoding=\"utf8\").read()\n",
    "parser = BeautifulSoup(contents, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "ste', 'waist'],\n ['way', 'weigh'],\n ['weak', 'week'],\n ['weather', 'whether'],\n ['where', 'wear'],\n ['which', 'witch'],\n [\"who''s\", 'whose'],\n ['won', 'one'],\n ['would', 'wood'],\n [\"you''re\", 'your']]"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "similar_7esl = []\n",
    "for element in parser.find_all(\"p\"):\n",
    "    candidate = element.find(\"strong\")\n",
    "    if candidate:\n",
    "        partitions = candidate.text.lower().split(\" —– \")\n",
    "        if len(partitions) > 1:\n",
    "            words = []\n",
    "            for p in partitions:\n",
    "                words.extend(s.strip().replace('’', \"''\") for s in p.split(\"/\"))\n",
    "            \n",
    "            similar_7esl.append(words)\n",
    "similar_7esl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [ku.txt](https://web.ku.edu/~edit/wordsall.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": ",\n ['wane', 'wain'],\n ['want', 'wont'],\n ['wean', 'ween'],\n ['wear', 'ware'],\n ['weather', 'wether', 'whether'],\n ['whither', 'wither'],\n ['worst', 'wurst'],\n ['yew', 'ewe', 'you'],\n ['yoke', 'yolk']]"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "contents = open(\"ku.txt\").read().lower().splitlines()[1:]\n",
    "similar_ku = [s.split(';') for s in contents]\n",
    "similar_ku"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [singularis.txt](http://www.singularis.ltd.uk/bifroest/misc/homophones-list.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'],\n ['whirled', 'world'],\n ['whit', 'wit'],\n ['white', 'wight'],\n [\"who's\", 'whose'],\n ['woe', 'whoa'],\n ['wood', 'would'],\n ['yaw', 'yore', 'your', \"you're\"],\n ['yoke', 'yolk'],\n [\"you'll\", 'yule']]"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "contents = open(\"singularis.txt\").read().lower().splitlines()[1:]\n",
    "similar_singularis = [s.split(', ') for s in contents]\n",
    "similar_singularis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [teachingtreasures.txt](https://www.teachingtreasures.com.au/teaching-tools/Basic-worksheets/worksheets-english/upper/homophones-list.htm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['wrap', 'rap'],\n ['wrapped', 'rapped'],\n ['wreak', 'reek'],\n ['wrest', 'rest'],\n ['wretch', 'retch'],\n ['wring', 'ring'],\n ['write', 'right'],\n ['wrote', 'rote'],\n ['wrung', 'rung'],\n ['wry', 'rye']]"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "contents = open(\"teachingtreasures.txt\").read().lower().splitlines()[1:]\n",
    "similar_teachingtreasures = [s.split(' ') for s in contents  if s]\n",
    "similar_teachingtreasures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [thoughtco](https://www.thoughtco.com/homonyms-homophones-and-homographs-a-b-1692660)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "],\n ['war', 'wore'],\n ['warn', 'worn'],\n ['way', 'weigh'],\n ['we', 'wee'],\n ['weak', 'week'],\n ['wear', 'where'],\n ['weather', 'whether'],\n ['which', 'witch'],\n ['wood', 'would'],\n ['your', \"you're\"]]"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "contents = open(\"thoughtco.txt\").read().lower().splitlines()[1:]\n",
    "similar_thoughtco = [s.split(' ') for s in contents  if s]\n",
    "similar_thoughtco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My personal list of words not found above\n",
    "\n",
    "These were identified through trial and error (actually, just error) during dictation. Pull Requests welcome. These words tend to be commonly confused, but are not generally recognized as homophones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[]"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "contents = open(\"dusty.txt\").read().lower().splitlines()[1:]\n",
    "similar_dusty = [s.split(' ') for s in contents  if s]\n",
    "similar_dusty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join it all together\n",
    "We want a list of all possible sets of words. This list of lists will surely contain duplicates (in fact, mostly duplicates).\n",
    "\n",
    "I have done a visual sanity check in all the outputs above, but I'll do another below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_words = []\n",
    "similar_words.extend(similar_7esl)\n",
    "similar_words.extend(similar_ku)\n",
    "similar_words.extend(similar_singularis)\n",
    "similar_words.extend(similar_teachingtreasures)\n",
    "similar_words.extend(similar_thoughtco)\n",
    "similar_words.extend(similar_dusty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = re.compile(\"^[a-z'-]+$\")\n",
    "for similar in similar_words:\n",
    "    if len(set(similar)) < 2:\n",
    "        print(similar)\n",
    "    for word in similar:\n",
    "        if not regex.match(word):\n",
    "            print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dedup\n",
    "\n",
    "Removing duplicates is not trivial, since the different sets of words may include multiple variations (for example, one set has *your* and *you're* and another includes *yore*). It would be easy enough to just do a double loop, but disjoint sets are my favourite datastructure, and I've never actually had an opportunity to use them in production code before. Read up on the union-find algorithm if you're unfamiliar with it, it's pretty cool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": " ['whither', 'wither'],\n [\"who''s\", \"who's\", 'whose'],\n ['whoa', 'woe'],\n ['wood', 'would'],\n ['worst', 'wurst'],\n ['yaw', 'yore', \"you''re\", \"you're\", 'your'],\n ['yoke', 'yolk'],\n [\"you'll\", 'yule']]"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "word_set = DisjointSet()\n",
    "for word_list in similar_words:\n",
    "    for word in word_list[1:]:\n",
    "        word_set.union(word_list[0], word)\n",
    "    \n",
    "wordsets = sorted(sorted(s) for s in word_set.itersets())\n",
    "wordsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "662"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "len(wordsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redupe\n",
    "\n",
    "The final output is a dictionary of words mapping to all the words similar to that word, not including that word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\n 'pries': ['prize'],\n 'prize': ['pries'],\n 'primer': ['primmer'],\n 'primmer': ['primer'],\n 'prince': ['prints'],\n 'prints': ['prince'],\n 'principal': ['principle'],\n 'principle': ['principal'],\n ...}"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "index = {}\n",
    "for similar in wordsets:\n",
    "    for word in similar:\n",
    "        local = similar.copy()\n",
    "        local.remove(word)\n",
    "        index[word] = local\n",
    "        \n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1440"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "len(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../similar_sounding_words.py\", \"w\") as file:\n",
    "    file.write(\"index = \" + pformat(index))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-candidate"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}